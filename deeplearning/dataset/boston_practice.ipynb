{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd742f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       506 non-null    float64\n",
      " 1   1       506 non-null    float64\n",
      " 2   2       506 non-null    float64\n",
      " 3   3       506 non-null    int64  \n",
      " 4   4       506 non-null    float64\n",
      " 5   5       506 non-null    float64\n",
      " 6   6       506 non-null    float64\n",
      " 7   7       506 non-null    float64\n",
      " 8   8       506 non-null    int64  \n",
      " 9   9       506 non-null    float64\n",
      " 10  10      506 non-null    float64\n",
      " 11  11      506 non-null    float64\n",
      " 12  12      506 non-null    float64\n",
      " 13  13      506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10      11    12    13\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3  396.90  4.98  24.0\n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8  396.90  9.14  21.6\n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8  392.83  4.03  34.7\n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7  394.63  2.94  33.4\n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7  396.90  5.33  36.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"./housing.csv\", delim_whitespace = True, header = None)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3912001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 20056.3125\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 1925.3600\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 742us/step - loss: 703.1190\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 740us/step - loss: 625.2917\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 771us/step - loss: 613.6478\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 644.6751\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 605.0916\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 748us/step - loss: 655.1075\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 752us/step - loss: 657.1848\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 750us/step - loss: 585.4776\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 743us/step - loss: 588.6399\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 624.4650\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 737us/step - loss: 582.7648\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 591.1735\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 739us/step - loss: 575.8204\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 573.7284\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 699us/step - loss: 556.6114\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 726us/step - loss: 594.8052\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 707us/step - loss: 591.9369\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 557.2388\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 734us/step - loss: 573.6880\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 715us/step - loss: 636.7092\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 744us/step - loss: 638.0409\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 745us/step - loss: 537.1685\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 792us/step - loss: 580.2076\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 746us/step - loss: 600.4361\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 543.4191\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 863us/step - loss: 575.4675\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 776us/step - loss: 589.4611\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 528.4308\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 700us/step - loss: 584.8097\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 796us/step - loss: 601.6177\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 547.6582\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 544.9698\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 552.1075\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 715us/step - loss: 589.0301\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 731us/step - loss: 578.3629\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 736us/step - loss: 549.5205\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 719us/step - loss: 564.7297\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 715us/step - loss: 565.3115\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 791us/step - loss: 545.1444\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 549.1719\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 778us/step - loss: 524.6942\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 751us/step - loss: 535.9515\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 578.4608\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 816us/step - loss: 537.8080\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 568.4175\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 557.8393\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 531.8066\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 544.4990\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 761us/step - loss: 539.6316\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 734us/step - loss: 537.8266\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 731us/step - loss: 556.4634\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 491.6547\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 765us/step - loss: 520.6314\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 518.7387\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 774us/step - loss: 543.0636\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 782us/step - loss: 544.6312\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 551.3309\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 746us/step - loss: 539.8721\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 774us/step - loss: 529.6416\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 767us/step - loss: 542.1569\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 805us/step - loss: 506.1036\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 716us/step - loss: 523.5403\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 786us/step - loss: 574.0648\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 522.4294\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 760us/step - loss: 491.4148\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 540.7912\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 587.4165\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 827us/step - loss: 528.0022\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 522.5532\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 516.1058\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 855us/step - loss: 553.6214\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 789us/step - loss: 520.3049\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 500.3841\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 799us/step - loss: 466.9413\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 715us/step - loss: 498.5484\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 748us/step - loss: 518.2746\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 559.8065\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - ETA: 0s - loss: 490.779 - 0s 725us/step - loss: 507.7163\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 772us/step - loss: 554.3756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 495.9535\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 828us/step - loss: 469.1505\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 512.9999\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 776us/step - loss: 486.7375\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 824us/step - loss: 510.8042\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 783us/step - loss: 487.0838\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 753us/step - loss: 461.6878\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 764us/step - loss: 506.7113\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 500.9126\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 775us/step - loss: 501.5503\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 711us/step - loss: 539.6747\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 505.8486\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 790us/step - loss: 489.0862\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 514.9008\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 731us/step - loss: 460.9589\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 786us/step - loss: 485.4952\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 824us/step - loss: 478.3689\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 816us/step - loss: 495.7088\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 498.1565\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 964us/step - loss: 465.2672\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 755us/step - loss: 492.9280\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 491.3417\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 791us/step - loss: 468.2072\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 727us/step - loss: 493.9959\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 776us/step - loss: 475.0261\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 804us/step - loss: 458.5545\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 737us/step - loss: 462.0478\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 702us/step - loss: 460.6328\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 751us/step - loss: 447.8090\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 445.0778\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 450.6251\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 749us/step - loss: 446.4406\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 782us/step - loss: 451.5509\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 807us/step - loss: 493.1429\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 459.2191\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 463.9514\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 473.9589\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 435.4305\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 746us/step - loss: 433.5233\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 762us/step - loss: 436.6218\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 827us/step - loss: 453.3460\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 777us/step - loss: 413.7564\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 759us/step - loss: 463.6218\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 754us/step - loss: 444.1847\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 810us/step - loss: 453.9823\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 701us/step - loss: 446.6421\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 758us/step - loss: 437.0849\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 738us/step - loss: 433.7368\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 787us/step - loss: 427.5089\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 725us/step - loss: 420.5056\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 742us/step - loss: 446.8712\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 753us/step - loss: 396.7505\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 733us/step - loss: 451.2230\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 758us/step - loss: 418.6413\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 421.6675\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 773us/step - loss: 446.4975\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 718us/step - loss: 398.9685\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 779us/step - loss: 432.9840\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 738us/step - loss: 400.8836\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 732us/step - loss: 422.7386\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 802us/step - loss: 438.5408\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 763us/step - loss: 446.1200\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 727us/step - loss: 432.5497\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 714us/step - loss: 410.9626\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 767us/step - loss: 417.5075\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 699us/step - loss: 410.7527\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 425.4022\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 717us/step - loss: 434.9836\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 729us/step - loss: 396.2038\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 793us/step - loss: 403.0158\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 752us/step - loss: 391.8021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 737us/step - loss: 437.2737\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 730us/step - loss: 423.2416\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 793us/step - loss: 379.8897\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 743us/step - loss: 395.6355\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 790us/step - loss: 390.9288\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 760us/step - loss: 428.8663\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 401.8438\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 816us/step - loss: 400.9731\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 775us/step - loss: 389.2178\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 771us/step - loss: 433.3372\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 775us/step - loss: 415.6783\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 394.3323\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 412.6851\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 367.1164\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 698us/step - loss: 401.2691\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 764us/step - loss: 378.7510\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 763us/step - loss: 423.1260\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 709us/step - loss: 399.2438\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 783us/step - loss: 377.8350\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 787us/step - loss: 408.8091\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 375.2147\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 734us/step - loss: 404.2991\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 761us/step - loss: 389.5346\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 402.6724\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 710us/step - loss: 382.1493\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 813us/step - loss: 413.3587\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 802us/step - loss: 373.5380\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 709us/step - loss: 362.7466\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 731us/step - loss: 335.0890\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 399.7486\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 718us/step - loss: 358.8600\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 750us/step - loss: 376.1984\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 794us/step - loss: 340.2740\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 351.1768\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 771us/step - loss: 395.9186\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 359.6727\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 359.4495\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 384.8935\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 383.9878\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 769us/step - loss: 394.6139\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 736us/step - loss: 350.4856\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 351.1759\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 732us/step - loss: 382.2243\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 362.2807\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 786us/step - loss: 334.7218\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 720us/step - loss: 319.1050\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 783us/step - loss: 337.7007\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 782us/step - loss: 375.8077\n",
      "실제가격: 22.600, 예상가격: 6.342\n",
      "실제가격: 50.000, 예상가격: 6.342\n",
      "실제가격: 23.000, 예상가격: 6.342\n",
      "실제가격: 8.300, 예상가격: 6.342\n",
      "실제가격: 21.200, 예상가격: 6.342\n",
      "실제가격: 19.900, 예상가격: 6.342\n",
      "실제가격: 20.600, 예상가격: 6.342\n",
      "실제가격: 18.700, 예상가격: 6.342\n",
      "실제가격: 16.100, 예상가격: 6.342\n",
      "실제가격: 18.600, 예상가격: 6.342\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"./housing.csv\", delim_whitespace = True, header = None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:13]\n",
    "y = dataset[:,13]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.3, random_state = seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer = 'adam')\n",
    "model.fit(X_train, Y_train, epochs = 200, batch_size = 10)\n",
    "\n",
    "y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05b0b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 26226.1426\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 951us/step - loss: 12247.4850\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 5315.7074\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 2187.0706\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1197.0852\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 868.1213\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 731.5965\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 744.9850\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 996us/step - loss: 704.3604\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 846us/step - loss: 621.3376\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 620.5801\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 643.8291\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 602.7513\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 596.1056\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 587.0023\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 585.1255\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 564.5824\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 896us/step - loss: 602.7822\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 605.1800\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 573.2654\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 597.3783\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 633.2150\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 871us/step - loss: 648.5194\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 555.7565\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 601.1523\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 608.1067\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 567.0223\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 604.0065\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 996us/step - loss: 602.4053\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 558.3493\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 603.1958\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 615.6997\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 582.9925\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 573.7672\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 998us/step - loss: 585.3417\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 803us/step - loss: 612.6424\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 607.8785\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 572.7364\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 590.6469\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 594.8232\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 995us/step - loss: 578.9166\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 588.1624\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 560.5334\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 576.5757\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 618.4002\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 580.5009\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 903us/step - loss: 605.9128\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 601.8133\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 573.7575\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 583.6369\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 586.2029\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 590.2023\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 604.1654\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 544.4897\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 565.6516\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 575.0881\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 592.6840\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 592.9919\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 590.0017\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 592.8704\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 582.9444\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 596.1801\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 559.3689\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 728us/step - loss: 580.1447\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 628.9068\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 579.2853\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 549.2660\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 600.6714\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 638.1729\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 996us/step - loss: 588.0984\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 863us/step - loss: 585.6796\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 911us/step - loss: 572.5040\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 995us/step - loss: 618.0146\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 724us/step - loss: 577.8272\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 567.2078\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 540.4971\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 572.8113\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 585.5181\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 630.7732\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 580.4619\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 614.6977\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 572.0360\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 542.5318\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 584.8273\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 565.5145\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 583.7712\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 569.6016\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 536.7735\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 588.2956\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 575.6162\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 853us/step - loss: 587.6744\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 625.1674\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 587.1530\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 576.9987\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 602.2627\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 903us/step - loss: 546.5802\n",
      "Epoch 97/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 726us/step - loss: 570.8597\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 570.7797\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 589.0842\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 591.0823\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 561.2590\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 585.4501\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 586.6981\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 715us/step - loss: 565.9026\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 579.2437\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 572.3975\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 564.3066\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 554.6180\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 566.1432\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 995us/step - loss: 544.7779\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 540.5798\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 903us/step - loss: 551.5245\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 550.3546\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 992us/step - loss: 554.2694\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 589.4732\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 566.1733\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 560.7330\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 574.4663\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 542.5766\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 541.5372\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 548.2509\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 561.8778\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 526.9012\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 575.2033\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 543.1307\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 558.4745\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 556.1287\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 551.0647\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 547.7543\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 550.3541\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 538.8141\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 561.0782\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 513.0037\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 569.3832\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 542.7848\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 545.9631\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 723us/step - loss: 561.9143\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 524.5617\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 553.9608\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 518.5385\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 548.8001\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 566.7834\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 567.4089\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 552.1470\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 538.5103\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 543.6962\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 536.3918\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 554.8253\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 567.5836\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 533.0510\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 530.0755\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 524.1479\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 942us/step - loss: 568.3396\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 558.3138\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 518.8703\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 529.4727\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 532.2243\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 571.4750\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 535.0417\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 539.5664\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 533.3133\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 574.8491\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 555.8149\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 537.9636\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 556.5360\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 511.9871\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 540.7837\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 516.1033\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 577.6057\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 545.8046\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 524.2736\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 546.7701\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 524.8498\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 550.1275\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 534.2967\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 558.2081\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 534.5638\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 557.9768\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 530.9702\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 513.9210\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 490.7317\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 566.7601\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 516.2921\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 536.1722\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 494.6767\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 508.4195\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 727us/step - loss: 546.3665\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 521.6572\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 520.2041\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 537.8453\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 545.6774\n",
      "Epoch 192/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 905us/step - loss: 553.5988\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 512.6583\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 512.6297\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 552.5334\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 727us/step - loss: 520.8312\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 500.8418\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 486.3228\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 509.4892\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 536.0795\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 541.6254\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 716us/step - loss: 505.7802\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 509.0019\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 513.7243\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 531.7342\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 823us/step - loss: 501.9381\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 533.3231\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 514.1927\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 473.3957\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 509.9006\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 500.0834\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 512.2798\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 994us/step - loss: 502.4236\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 526.5784\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 530.2524\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 507.2123\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 998us/step - loss: 501.2035\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 526.4583\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 515.2671\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 543.9035\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 501.8699\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 493.9523\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 518.3540\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 508.0735\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 512.1970\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 515.6158\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 996us/step - loss: 492.4484\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 812us/step - loss: 498.7526\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 500.9691\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 515.6206\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 570.4019\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 497.5663\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 471.8215\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 495.7083\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 525.7024\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 727us/step - loss: 460.0310\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 556.7996\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 497.5218\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 536.8881\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 486.3877\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 503.7373\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 467.3120\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 496.0865\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 835us/step - loss: 483.5858\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 482.0393\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 469.6314\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 523.3541\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 496.2769\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 507.5443\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 493.7038\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 503.1289\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 728us/step - loss: 487.8399\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 775us/step - loss: 471.8393\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 491.0983\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 494.6594\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 495.9734\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 995us/step - loss: 512.7100\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 498.2818\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 506.9917\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 491.8517\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 517.0039\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 522.6934\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 911us/step - loss: 494.8313\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 481.7907\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 491.8627\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 475.6957\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 502.9707\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 488.3664\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 509.6761\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 490.9704\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 466.5632\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 811us/step - loss: 499.2326\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 483.9559\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 495.1510\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 520.7653\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 485.8839\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 445.7282\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 497.2538\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 435.2986\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 492.0799\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 459.6832\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 493.4872\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 477.2235\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 463.1041\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 492.1322\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 812us/step - loss: 500.2869\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 816us/step - loss: 502.3847\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 478.1623\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 726us/step - loss: 485.6963\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 476.9040\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 507.3859\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 456.3208\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 473.6378\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 453.6675\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 446.0617\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 499.4627\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 474.3082\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 466.2674\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 485.7293\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 482.0667\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 492.8529\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 471.3125\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 492.4438\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 728us/step - loss: 477.1976\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 461.2123\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 492.7893\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 497.9523\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 477.7615\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 482.7398\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 435.2458\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 495.1478\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 435.0658\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 994us/step - loss: 459.4481\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 462.0364\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 506.6874\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 488.0117\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 455.0974\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 490.2444\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 462.7804\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 457.0287\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 473.3545\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 484.2129\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 454.0405\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 498.8023\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 437.0423\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 450.1751\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 478.7209\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 443.5126\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 477.2326\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 512.9571\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 439.5973\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 466.9167\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 442.9964\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 485.0880\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 459.1022\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 790us/step - loss: 487.7407\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 467.3160\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 441.1817\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 498.7372\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 441.4172\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 406.5162\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 457.2782\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 424.0574\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 812us/step - loss: 470.7329\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 466.4125\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 462.2610\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 484.2081\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 481.0897\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 420.4479\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 463.3011\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 444.9025\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 475.1262\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 844us/step - loss: 446.6663\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 812us/step - loss: 471.7218\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 428.9419\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 783us/step - loss: 478.0028\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 439.9275\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 461.2728\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 727us/step - loss: 472.6825\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 446.8386\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 429.7702\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 452.8251\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 463.7271\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 471.4044\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 465.8751\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 409.8393\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 441.2750\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 444.5294\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 437.2838\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 427.2437\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 450.2712\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 447.5986\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 436.6756\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 448.2336\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 430.9296\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 422.1079\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 454.5065\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 452.8669\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 437.2811\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 825us/step - loss: 462.7021\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 450.5349\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 907us/step - loss: 411.0140\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 435.9322\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 439.1773\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 458.2716\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 414.1568\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 456.7637\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 723us/step - loss: 461.6096\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 775us/step - loss: 442.2465\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 427.4085\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 411.2037\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 426.6383\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 436.6882\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 428.7844\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 846us/step - loss: 438.1471\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 449.5630\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 432.8568\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 726us/step - loss: 456.6657\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 428.6770\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 419.9175\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 442.6578\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 820us/step - loss: 440.4934\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 435.7955\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 724us/step - loss: 428.4130\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 422.0504\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 443.0985\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 427.9969\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 728us/step - loss: 436.9529\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 447.6171\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 441.9358\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 454.1696\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 426.3980\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 448.3244\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 408.0470\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 385.8632\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 392.5684\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 434.7534\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 426.0105\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 411.3094\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 813us/step - loss: 411.4036\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 458.5627\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 432.4008\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 433.2605\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 440.2739\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 391.5165\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 411.3102\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 411.4747\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 720us/step - loss: 418.6409\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 386.6520\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 391.2492\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 393.4325\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 412.8265\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 395.8091\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 426.2939\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 423.8859\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 403.9220\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 459.0976\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 440.2128\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 446.4025\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 366.8123\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 406.4259\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 362.0317\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 443.2656\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 417.5947\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 398.9951\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 444.7574\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 812us/step - loss: 392.2751\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 379.0516\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 385.1605\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 811us/step - loss: 436.0746\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 401.7184\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 906us/step - loss: 412.4756\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 406.2853\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 398.3393\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 426.6747\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 415.3951\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 401.9537\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 402.5542\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 388.3922\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 401.9649\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 417.3504\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 312.695 - 0s 816us/step - loss: 385.9171\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 411.3794\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 412.4844\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 818us/step - loss: 393.6891\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 395.1105\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 358.2859\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 995us/step - loss: 424.2510\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 423.9181\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 820us/step - loss: 402.1287\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 397.5661\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 409.8637\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 379.5934\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 402.5195\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 400.9265\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 385.7203\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 907us/step - loss: 387.5287\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 814us/step - loss: 359.3231\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 423.9003\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 811us/step - loss: 398.6930\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 411.4981\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 404.7851\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 380.0779\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 382.2081\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 816us/step - loss: 407.0828\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 998us/step - loss: 390.4808\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 390.9918\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 404.2156\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 398.3007\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 387.0457\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 425.9806\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 382.2676\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 417.5179\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 399.8737\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 728us/step - loss: 385.0720\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 907us/step - loss: 401.6944\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 995us/step - loss: 415.0016\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 368.3264\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 908us/step - loss: 387.3089\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 904us/step - loss: 432.3701\n",
      "실제가격: 22.600, 예상가격: 5.258\n",
      "실제가격: 50.000, 예상가격: 5.258\n",
      "실제가격: 23.000, 예상가격: 5.258\n",
      "실제가격: 8.300, 예상가격: 5.258\n",
      "실제가격: 21.200, 예상가격: 5.258\n",
      "실제가격: 19.900, 예상가격: 5.258\n",
      "실제가격: 20.600, 예상가격: 5.258\n",
      "실제가격: 18.700, 예상가격: 5.258\n",
      "실제가격: 16.100, 예상가격: 5.258\n",
      "실제가격: 18.600, 예상가격: 5.258\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"./housing.csv\", delim_whitespace=True, header=None)\n",
    "'''\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "'''\n",
    "dataset = df.values\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=500, batch_size=30)\n",
    "\n",
    "# 예측 값과 실제 값의 비교\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341f2381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 781us/step - loss: 20056.3125\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 805us/step - loss: 1925.3600\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 743us/step - loss: 703.1190\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 735us/step - loss: 625.2917\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 776us/step - loss: 613.6478\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 644.6751\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 605.0916\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 819us/step - loss: 655.1075\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 813us/step - loss: 657.1848\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 835us/step - loss: 585.4776\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 808us/step - loss: 588.6399\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 801us/step - loss: 624.4650\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 859us/step - loss: 582.7648\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 787us/step - loss: 591.1735\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 575.8204\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 784us/step - loss: 573.7284\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 556.6114\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 845us/step - loss: 594.8052\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 771us/step - loss: 591.9369\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 765us/step - loss: 557.2388\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 743us/step - loss: 573.6880\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 811us/step - loss: 636.7092\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 846us/step - loss: 638.0409\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 809us/step - loss: 537.1685\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 782us/step - loss: 580.2076\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 746us/step - loss: 600.4361\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 543.4191\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 835us/step - loss: 575.4675\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 589.4611\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 799us/step - loss: 528.4308\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 841us/step - loss: 584.8097\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 776us/step - loss: 601.6177\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 817us/step - loss: 547.6582\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 852us/step - loss: 544.9698\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 811us/step - loss: 552.1075\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 849us/step - loss: 589.0301\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 790us/step - loss: 578.3629\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 549.5205\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 564.7297\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 565.3115\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 758us/step - loss: 545.1444\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 808us/step - loss: 549.1719\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 818us/step - loss: 524.6942\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 787us/step - loss: 535.9515\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 814us/step - loss: 578.4608\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 772us/step - loss: 537.8080\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 568.4175\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 812us/step - loss: 557.8393\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 763us/step - loss: 531.8066\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 544.4990\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 539.6316\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 537.8266\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 771us/step - loss: 556.4634\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 827us/step - loss: 491.6547\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 807us/step - loss: 520.6314\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 883us/step - loss: 518.7387\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 543.0636\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 843us/step - loss: 544.6312\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 789us/step - loss: 551.3309\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 539.8721\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 783us/step - loss: 529.6416\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 542.1569\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 777us/step - loss: 506.1036\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 759us/step - loss: 523.5403\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 574.0648\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 522.4294\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 767us/step - loss: 491.4148\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 765us/step - loss: 540.7912\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 587.4165\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 719us/step - loss: 528.0022\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 522.5532\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 752us/step - loss: 516.1058\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 806us/step - loss: 553.6214\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 520.3049\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 500.3841\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 466.9413\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 793us/step - loss: 498.5484\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 780us/step - loss: 518.2746\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 839us/step - loss: 559.8065\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 507.7163\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 789us/step - loss: 554.3756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 792us/step - loss: 495.9535\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 782us/step - loss: 469.1505\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 742us/step - loss: 512.9999\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 782us/step - loss: 486.7375\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 510.8042\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 760us/step - loss: 487.0838\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 461.6878\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 738us/step - loss: 506.7113\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 784us/step - loss: 500.9126\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 767us/step - loss: 501.5503\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 838us/step - loss: 539.6747\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 505.8486\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 489.0862\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 761us/step - loss: 514.9008\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 460.9589\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 715us/step - loss: 485.4952\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 763us/step - loss: 478.3689\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 746us/step - loss: 495.7088\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 748us/step - loss: 498.1565\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 680us/step - loss: 465.2672\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 696us/step - loss: 492.9280\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 784us/step - loss: 491.3417\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 758us/step - loss: 468.2072\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 493.9959\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 764us/step - loss: 475.0261\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 458.5545\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 719us/step - loss: 462.0478\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 743us/step - loss: 460.6328\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 447.8090\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 662us/step - loss: 445.0778\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 450.6251\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 446.4406\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 700us/step - loss: 451.5509\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 715us/step - loss: 493.1429\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 751us/step - loss: 459.2191\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 463.9514\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 721us/step - loss: 473.9589\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 707us/step - loss: 435.4305\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 745us/step - loss: 433.5233\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 676us/step - loss: 436.6218\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 720us/step - loss: 453.3460\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 742us/step - loss: 413.7564\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 463.6218\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 444.1847\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 453.9823\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 446.6421\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 753us/step - loss: 437.0849\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 433.7368\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 774us/step - loss: 427.5089\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 802us/step - loss: 420.5056\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 786us/step - loss: 446.8712\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 396.7505\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 451.2230\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 418.6413\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 822us/step - loss: 421.6675\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 748us/step - loss: 446.4975\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 398.9685\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 432.9840\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 753us/step - loss: 400.8836\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 685us/step - loss: 422.7386\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 438.5408\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 765us/step - loss: 446.1200\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 673us/step - loss: 432.5497\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 410.9626\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 417.5075\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 410.7527\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 739us/step - loss: 425.4022\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 752us/step - loss: 434.9836\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 723us/step - loss: 396.2038\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 686us/step - loss: 403.0158\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 897us/step - loss: 391.8021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 787us/step - loss: 437.2737\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 423.2416\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 747us/step - loss: 379.8897\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 755us/step - loss: 395.6355\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 390.9288\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 715us/step - loss: 428.8663\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 733us/step - loss: 401.8438\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 745us/step - loss: 400.9731\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 694us/step - loss: 389.2178\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 752us/step - loss: 433.3372\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 415.6783\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 709us/step - loss: 394.3323\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 742us/step - loss: 412.6851\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 367.1164\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 762us/step - loss: 401.2691\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 378.7510\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 743us/step - loss: 423.1260\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 715us/step - loss: 399.2438\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 764us/step - loss: 377.8350\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 754us/step - loss: 408.8091\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 736us/step - loss: 375.2147\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 699us/step - loss: 404.2991\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 389.5346\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 402.6724\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 729us/step - loss: 382.1493\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 771us/step - loss: 413.3587\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 761us/step - loss: 373.5380\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 731us/step - loss: 362.7466\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 727us/step - loss: 335.0890\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 399.7486\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 786us/step - loss: 358.8600\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 376.1984\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 340.2740\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 351.1768\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 395.9186\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 738us/step - loss: 359.6727\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 742us/step - loss: 359.4495\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 717us/step - loss: 384.8935\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 754us/step - loss: 383.9878\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 712us/step - loss: 394.6139\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 745us/step - loss: 350.4856\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 753us/step - loss: 351.1759\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 754us/step - loss: 382.2243\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 698us/step - loss: 362.2807\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 787us/step - loss: 334.7218\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 319.1050\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 337.7007\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 792us/step - loss: 375.8077\n",
      "[6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.2823496 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3213434 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 5.4046836 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.2361317 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706\n",
      " 6.3417706 6.3417706 6.3417706 6.3417706 6.3417706]\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"../dataset/housing.csv\", delim_whitespace=True, header=None)\n",
    "'''\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "'''\n",
    "dataset = df.values\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
    "\n",
    "# 예측 값과 실제 값의 비교\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e36331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 2ms/step - loss: 20056.3125\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1925.3600\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 703.1190\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 625.2917\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 613.6478\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 644.6751\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 605.0916\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 655.1075\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 657.1848\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 585.4776\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 588.6399\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 624.4650\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 582.7648\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 591.1735\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 575.8204\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 573.7284\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 556.6114\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 594.8052\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 591.9369\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 557.2388\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 573.6880\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 636.7092\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 638.0409A: 0s - loss: 680.074\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 537.1685\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 580.2076\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 600.4361\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 543.4191\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 575.4675\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 589.4611\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 528.4308\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 584.8097\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 601.6177\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 547.6582\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 544.9698\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 552.1075\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 589.0301\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 578.3629\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 549.5205\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 564.7297\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 565.3115\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 545.1444\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 549.1719\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 524.6942\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 535.9515\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 578.4608\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 537.8080\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - ETA: 0s - loss: 570.841 - 0s 2ms/step - loss: 568.4175\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 557.8393\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 531.8066\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 544.4990\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 539.6316\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 537.8266\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 556.4634\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 491.6547\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 520.6314\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 518.7387\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 543.0636\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 544.6312\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 551.3309\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 539.8721\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 529.6416\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 542.1569\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 506.1036\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 523.5403\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 574.0648\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 522.4294\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 491.4148\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 540.7912\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 587.4165\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 528.0022\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 522.5532\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 516.1058\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 553.6214\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 520.3049\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 500.3841\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 466.9413\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 498.5484\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 518.2746\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 559.8065\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 507.7163\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 554.3756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 495.9535\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 469.1505\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 512.9999\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 486.7375\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 510.8042\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 487.0838\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 461.6878\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 506.7113\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 500.9126\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 501.5503\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 539.6747\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 505.8486\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 489.0862\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 514.9008\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 460.9589\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 485.4952\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 478.3689\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 684us/step - loss: 495.7088\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 498.1565\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 465.2672\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 492.9280\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 940us/step - loss: 491.3417\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 468.2072\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 493.9959\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 475.0261\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 458.5545\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 462.0478\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 460.6328\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 447.8090\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 445.0778\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 450.6251\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 446.4406\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 451.5509\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 493.1429\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 459.2191\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 463.9514\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 473.9589\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 435.4305\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 433.5233\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 436.6218\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 453.3460\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 413.7564\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 463.6218\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 444.1847\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 453.9823\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 446.6421\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 437.0849\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 433.7368\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 427.5089\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 420.5056\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 446.8712\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 396.7505\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 451.2230\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 418.6413\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 421.6675\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 446.4975\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 398.9685\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 432.9840\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 400.8836\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 422.7386\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 438.5408\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 446.1200\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 432.5497\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 410.9626\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 417.5075\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 410.7527\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 425.4022\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 434.9836\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 396.2038\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 403.0158\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 391.8021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 437.2737\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 423.2416\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 379.8897\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 395.6355\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 390.9288\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 428.8663\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 401.8438\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 400.9731\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 389.2178\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 433.3372\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 415.6783\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 394.3323\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 412.6851\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 367.1164\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 401.2691\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 378.7510\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 423.1260\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 399.2438\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 377.8350\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 408.8091\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 375.2147\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 404.2991\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 389.5346A: 0s - loss: 389.968\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 402.6724\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 382.1493\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 413.3587\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 373.5380\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 362.7466\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 335.0890\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 399.7486\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 358.8600\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 376.1984\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - ETA: 0s - loss: 320.523 - 0s 3ms/step - loss: 340.2740\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 351.1768\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 395.9186\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 359.6727\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 359.4495\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 384.8935\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 383.9878\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 394.6139\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 350.4856\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 351.1759\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 382.2243\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 362.2807\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 334.7218\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 319.1050\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 337.7007\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 375.8077\n",
      "실제가격: 22.600, 예상가격: 6.342\n",
      "실제가격: 50.000, 예상가격: 6.342\n",
      "실제가격: 23.000, 예상가격: 6.342\n",
      "실제가격: 8.300, 예상가격: 6.342\n",
      "실제가격: 21.200, 예상가격: 6.342\n",
      "실제가격: 19.900, 예상가격: 6.342\n",
      "실제가격: 20.600, 예상가격: 6.342\n",
      "실제가격: 18.700, 예상가격: 6.342\n",
      "실제가격: 16.100, 예상가격: 6.342\n",
      "실제가격: 18.600, 예상가격: 6.342\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"../dataset/housing.csv\", delim_whitespace=True, header=None)\n",
    "'''\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "'''\n",
    "dataset = df.values\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
    "\n",
    "# 예측 값과 실제 값의 비교\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a46dd30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       506 non-null    float64\n",
      " 1   1       506 non-null    float64\n",
      " 2   2       506 non-null    float64\n",
      " 3   3       506 non-null    int64  \n",
      " 4   4       506 non-null    float64\n",
      " 5   5       506 non-null    float64\n",
      " 6   6       506 non-null    float64\n",
      " 7   7       506 non-null    float64\n",
      " 8   8       506 non-null    int64  \n",
      " 9   9       506 non-null    float64\n",
      " 10  10      506 non-null    float64\n",
      " 11  11      506 non-null    float64\n",
      " 12  12      506 non-null    float64\n",
      " 13  13      506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2   3      4      5     6       7   8      9     10  \\\n",
       "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...   \n",
       "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0   \n",
       "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0   \n",
       "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0   \n",
       "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0   \n",
       "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0   \n",
       "\n",
       "         11    12    13  \n",
       "0    396.90  4.98  24.0  \n",
       "1    396.90  9.14  21.6  \n",
       "2    392.83  4.03  34.7  \n",
       "3    394.63  2.94  33.4  \n",
       "4    396.90  5.33  36.2  \n",
       "..      ...   ...   ...  \n",
       "501  391.99  9.67  22.4  \n",
       "502  396.90  9.08  20.6  \n",
       "503  396.90  5.64  23.9  \n",
       "504  393.45  6.48  22.0  \n",
       "505  396.90  7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "import pandas as pd\n",
    "pd.read_csv('https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/boston.csv', delim_whitespace = True, header = None)\n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb5bb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 792us/step - loss: 20056.3125\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 1925.3600\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 703.1190\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 817us/step - loss: 625.2917\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 814us/step - loss: 613.6478\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 644.6751\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 605.0916\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 728us/step - loss: 655.1075\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 790us/step - loss: 657.1848\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 585.4776\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 588.6399\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 624.4650\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 582.7648\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 855us/step - loss: 591.1735\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 755us/step - loss: 575.8204\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 573.7284\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 556.6114\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 594.8052\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 764us/step - loss: 591.9369\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 557.2388\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 573.6880\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 636.7092\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 638.0409\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 537.1685\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 580.2076\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 816us/step - loss: 600.4361\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 821us/step - loss: 543.4191\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 805us/step - loss: 575.4675\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 766us/step - loss: 589.4611\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 528.4308\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 845us/step - loss: 584.8097\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 814us/step - loss: 601.6177\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 547.6582\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 544.9698\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 731us/step - loss: 552.1075\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 793us/step - loss: 589.0301\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 779us/step - loss: 578.3629\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 752us/step - loss: 549.5205\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 716us/step - loss: 564.7297\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 565.3115\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 739us/step - loss: 545.1444\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 685us/step - loss: 549.1719\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 801us/step - loss: 524.6942\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 762us/step - loss: 535.9515\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 750us/step - loss: 578.4608\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 537.8080\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 733us/step - loss: 568.4175\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 736us/step - loss: 557.8393\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 531.8066\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 544.4990\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 819us/step - loss: 539.6316\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 785us/step - loss: 537.8266\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 556.4634\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 491.6547\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 807us/step - loss: 520.6314\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 799us/step - loss: 518.7387\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 543.0636\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 544.6312\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 551.3309\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 737us/step - loss: 539.8721\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 734us/step - loss: 529.6416\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 761us/step - loss: 542.1569\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 506.1036\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 523.5403\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 574.0648\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 744us/step - loss: 522.4294\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 760us/step - loss: 491.4148\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 771us/step - loss: 540.7912\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 587.4165\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 528.0022\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 710us/step - loss: 522.5532\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 516.1058\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 756us/step - loss: 553.6214\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 520.3049\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 500.3841\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 466.9413\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 498.5484\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 518.2746\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 559.8065\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 779us/step - loss: 507.7163\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 554.3756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 744us/step - loss: 495.9535\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 797us/step - loss: 469.1505\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 698us/step - loss: 512.9999\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 486.7375\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 750us/step - loss: 510.8042\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 487.0838\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 757us/step - loss: 461.6878\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 506.7113\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 779us/step - loss: 500.9126\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 501.5503\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 539.6747\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 505.8486\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 489.0862\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 711us/step - loss: 514.9008\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 460.9589\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 710us/step - loss: 485.4952\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 740us/step - loss: 478.3689\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 763us/step - loss: 495.7088\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 753us/step - loss: 498.1565\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 465.2672\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 751us/step - loss: 492.9280\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 765us/step - loss: 491.3417\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 685us/step - loss: 468.2072\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 493.9959\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 475.0261\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 722us/step - loss: 458.5545\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 736us/step - loss: 462.0478\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 460.6328\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 685us/step - loss: 447.8090\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 445.0778\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 450.6251\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 955us/step - loss: 446.4406\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 752us/step - loss: 451.5509\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 493.1429\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 764us/step - loss: 459.2191\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 726us/step - loss: 463.9514\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 711us/step - loss: 473.9589\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 435.4305\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 433.5233\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 791us/step - loss: 436.6218\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 453.3460\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 413.7564\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 463.6218\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 444.1847\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 453.9823\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 883us/step - loss: 446.6421\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 437.0849\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 433.7368\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 761us/step - loss: 427.5089\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 770us/step - loss: 420.5056\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 446.8712\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 396.7505\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 730us/step - loss: 451.2230\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 724us/step - loss: 418.6413\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 742us/step - loss: 421.6675\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 446.4975\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 398.9685\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 432.9840\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 400.8836\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 759us/step - loss: 422.7386\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 438.5408\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 745us/step - loss: 446.1200\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 721us/step - loss: 432.5497\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 410.9626\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 417.5075\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 713us/step - loss: 410.7527\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 705us/step - loss: 425.4022\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 769us/step - loss: 434.9836\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 741us/step - loss: 396.2038\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 740us/step - loss: 403.0158\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 800us/step - loss: 391.8021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 437.2737\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 798us/step - loss: 423.2416\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 379.8897\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 615us/step - loss: 395.6355\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 627us/step - loss: 390.9288\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 656us/step - loss: 428.8663\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 401.8438\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 400.9731\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 740us/step - loss: 389.2178\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 433.3372\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 415.6783\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 394.3323\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 656us/step - loss: 412.6851\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 367.1164\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 401.2691\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 378.7510\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 423.1260\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 399.2438\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 377.8350\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 408.8091\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 375.2147\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 404.2991\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 389.5346\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 628us/step - loss: 402.6724\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 382.1493\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 413.3587\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 373.5380\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 628us/step - loss: 362.7466\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 335.0890\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 399.7486\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 358.8600\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 376.1984\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 340.2740\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 662us/step - loss: 351.1768\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 395.9186\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 712us/step - loss: 359.6727\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 359.4495\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 384.8935\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 627us/step - loss: 383.9878\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 684us/step - loss: 394.6139\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 350.4856\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 657us/step - loss: 351.1759\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 382.2243\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 362.2807\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 334.7218\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 672us/step - loss: 319.1050\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 684us/step - loss: 337.7007\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 375.8077\n",
      "실제가격: 22.600, 예상가격: 6.342\n",
      "실제가격: 50.000, 예상가격: 6.342\n",
      "실제가격: 23.000, 예상가격: 6.342\n",
      "실제가격: 8.300, 예상가격: 6.342\n",
      "실제가격: 21.200, 예상가격: 6.342\n",
      "실제가격: 19.900, 예상가격: 6.342\n",
      "실제가격: 20.600, 예상가격: 6.342\n",
      "실제가격: 18.700, 예상가격: 6.342\n",
      "실제가격: 16.100, 예상가격: 6.342\n",
      "실제가격: 18.600, 예상가격: 6.342\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0 \n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:13]\n",
    "Y = dataset[ :, 13] \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, \n",
    "                                                    random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim =13, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
    "\n",
    "# 예측값과 실제 값의 비교 \n",
    "Y_priediction = model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(10): \n",
    "    label = Y_test[i]\n",
    "    prediction = Y_priediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
